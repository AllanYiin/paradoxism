# `@agent` 裝飾器

## 概述

`@agent` 是一個 Python 裝飾器，用於將函數標記為可由 LLM（如 GPT-4）執行的**重複性**任務單位。通過將該裝飾器應用於函數，可以實現以下功能:

* 於後台配置LLM Client以調用大型語言模型
* 可以維護固定的system prompt，以及靜態instruction，兩者的差別在於前者是角色扮演的人設，後者則是對執行任務的方法步驟說明
* 輸入引數加上型別註記（Type Hinting）則可以對型別做強制檢查與轉型
* 在函數內可以透過prompt函數調用大型語言模型執行較複雜的語意處理，而輸出結果可以透過型別註記（Type Hinting）對型別做強制檢查與轉型
* @agent本質應該會是一個會被**重複調用**的最小任務

---

## 關於@agent

---

1. [設計概念](#%E8%A8%AD%E8%A8%88%E6%A6%82%E5%BF%B5)
2. [主要用途](#%E4%B8%BB%E8%A6%81%E7%94%A8%E9%80%94)
3. [輸入與輸出引數定義](#%E8%BC%B8%E5%85%A5%E8%88%87%E8%BC%B8%E5%87%BA%E5%BC%95%E6%95%B8%E5%AE%9A%E7%BE%A9)
4. [使用案例](#%E4%BD%BF%E7%94%A8%E6%A1%88%E4%BE%8B)

---

### @agent設計概念

`agent` 裝飾器旨在讓開發者簡單、靈活地將 LLM 集成到應用程式中。

在paradoxism中，是以函數的裝飾器來構成agent，而所謂偽代碼指的是有函數的形式，但是執行細節卻是透過自然語言prompt，在此我們可以透過系統提示、靜態指令與動態指令這三者來實現。

#### 👉系統提示 (System Prompt)

系統提示是為 LLM 提供的角色設定，通常告訴模型它應該扮演什麼樣的角色，以及它需要根據什麼樣的背景知識來生成回應。在 `@agent` 裝飾器中，`system_prompt` 參數指定了這個角色設定。系統提示的設置應該簡明扼要，並充分描述模型在回應時的行為。例如，在情感偵測案例中，系統提示可以是：

```python
system_prompt='你是一個擅長中文情感偵測的超級專家'
```

這樣，模型就會知道在生成文本回應時，它的角色是情感偵測專家，並將根據該背景來處理輸入。

---

### 👉靜態指令 (Static Instruction)

靜態指令是執行任務的背景資訊以及行動準則。這通常是在系統提示之外，為任務設置一些不變的上下文規則，例如如何分類不同的情感，如何從輸入中解析這些情感。這部分屬於內嵌在函數中的邏輯，是 LLM 在提供輸出時會參考的固定規則。

靜態指令維護於該函數的docstring中，雖說是靜態指令，但是也可以透過string.format來嵌套輸入引數，以實現小幅度的動態邏輯

例如，靜態指令可以告訴模型情感分類的方式：

```python
@agent(model='gpt-4o-mini',system_prompt='你是一個擅長中文情感偵測的超級幫手')
def emotion_detection(sentence: str) -> dict:
    """
    - 需要偵測的情感類型:
        正面情緒(positive_emotions)=[自信,快樂,體貼,幸福,信任,喜愛,尊榮,期待,感動,感謝,熱門,獨特,稱讚]
        負面情緒(negative_emotions)=[失望,危險,後悔,冷漠,懷疑,恐懼,悲傷,憤怒,擔心,無奈,煩悶,虛假,討厭,貶責,輕視]
  
    """
    results = prompt('input:'+sentence+'\n\n'+'當句子中有符合以上任何情感類型時，請盡可能的將符合的「情感類型」(key)及句子中的那些「觸及到情感類型的句子文字內容」(value)成對的列舉出來，一個句子可以觸及不只一種情感，請以dict形式輸出')
    return results
```

---

### 👉動態指令 (Dynamic Instruction)

LLM 的生成邏輯是根據具體的輸入，模型動態生成的部分。與靜態指令不同，這部分隨著輸入的不同而改變。模型會根據輸入的語境，匹配靜態指令中的情感分類，並生成合適的結果。例如：

```python
results: object = prompt('input:'+sentence+'\n\n'+'當句子中有符合以上任何情感類型時，請盡可能的將符合的「情感類型」(key)及句子中的那些「觸及到情感類型的句子文字內容」(value)成對的列舉出來，一個句子可以觸及不只一種情感，請以dict形式輸出')
```

這裡，模型會根據 `sentence` 的內容，使用靜態指令中的情感分類來匹配輸入的語句，並動態生成回應。

---

### 主要用途

* **翻譯**：可結合 LLM 完成多語種翻譯任務，保持原文的風格和意境。
* **內容生成**：根據用戶的輸入動態生成文本。
* **文檔審閱**：透過 LLM 的語言能力來審閱、優化文本，提供具體的改善意見。
* **其他自動化任務**：各種需要自然語言處理的任務單元。

---

### 輸入與輸出引數定義

#### `@agent` 的參數

* **model**: `str`，指定使用的 LLM 模型名稱。例如 `'gpt-4'`。
* **system\_prompt**: `str`，提供給 LLM 的系統提示語。這是模型在回應時考慮的上下文基礎。
* **temperature**: `float`，可選，控制生成內容的隨機性。較低的值會使模型更確定性，較高的值會使模型產生更多變的回應。默認值為 `0.7`。
* **kwargs**: 其他可選參數，將傳遞給 LLM 客戶端。

#### 包裝函數的輸入與輸出

* 包裝的函數可以接收任意數量的參數（\*args 和 \*\*kwargs）。
* 函數執行後會返回 LLM 的生成結果，通常是一個字符串。

---

### 使用案例

#### 案例一：多語言翻譯器

```python
from paradoxism.base.agent import agent
from paradoxism.ops.base import prompt

@agent(model='gpt-4', system_prompt='你是一個擅長多國語言的的翻譯高手...')
def translator(input_string, to_language):
    """
    利用 LLM 進行語言翻譯，保持原文的風格和言外之意。

    Args:
    input_string (str): 需要翻譯的原始文本。
    to_language (str): 要翻譯的目標語言。

    Returns:
    str: 翻譯後的文本。
    """

    translated_result = prompt(f'請將以下內容翻譯成{to_language}...')
    return translated_result
```

#### 案例二：翻譯質量審閱

```python
@agent(model='gpt-4o',system_prompt='你是一個30年口譯經驗的專家')
def rethinker(input_string, translated_string, to_language):
f"""
你熟悉{to_language}語言的各種細膩的處理技巧，以下是你針對翻譯上的幾個重要堅持:

- 你會檢視原文中有無字義未被納入在譯文裡，以及譯文中有無對於原文過度翻譯或者是意義背離的問題

- 如果因為語言間的差異有些幽默點或者是精心設計的文字趣味無法直接翻譯，以也會建議在{to_language}可以怎麼處理來致敬原文的設計精巧之處

- 若是原文中有包括諷刺、暗喻、隱喻等修辭技巧，以應該要呈現在譯文之中
- 如果是詩詞，則會重視發音的節奏與押韻，盡量能將原文的音律巧妙的重現於譯文中
- 如果是涉及人名、地名、公司名...等專有名詞，則應與{to_language}中通用性稱呼一致
  """
  comment =prompt(f'以下兩段文字，第一段是原文，第二段是翻譯為{to_language}的譯文，請你針對這樣的翻譯是否還有可以更精進優化的空間給予具體的改進意見，以及那些是你覺得值得讚賞的優秀之處?你只提出觀點與看法，不要提供整份調整後譯文\n\n"""{input_string}"""\n\n"""{translated_string}"""')
  return comment
```

這兩個案例展示了如何利用 `@agent` 裝飾器來進行翻譯和審閱功能。

---

### 效能記錄

在 `@agent` 裝飾器中，會自動記錄每次 LLM 任務執行的性能數據。這些數據將保存在 `PerformanceCollector` 中，方便後續進行效能分析。
